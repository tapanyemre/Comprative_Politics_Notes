
# Metadata
## Identifiers
title: Rethinking Social Inquiry: Diverse Tools, Shared Standards
author(s): David #Collier , Henry E. #Brady
year: #y2004
citation:
link:

## Linkers

sub-theme(s): #Methodology #Qualitative
keywords:

## Body

from: 
cohort:

## TLDR

RQ:
Main Argument:
DV:
IV:
Main Findings:
Data:
Method:
Empirical Evidence: 
How does the evidence map onto the theoretical argument: 

# Long Summary

## Chapter 1

There is a tension between quantitative and qualitative scholars. KKV
suggested that qualitative scholars use quantitative template (tacitly
implied superiority of quantitative techniques). By doing so KKV
summarized and outlined a very useful approach for thinking about
research design that is used today by both quantitative and qualitative
scholars. Some qualitative scholars accepted some of KKV's suggestion
others argued that quantitative and qualitative approaches are
completely different.

Authors of this book argue that both quantitative and qualitative can
learn from each other a lot. They use KKV's book as a basis for the
discussion (Designing Social Inquiry: Scientific Inference in
Qualitative Research , by Gary King, Robert O. Keohane, and Sidney
Verba).

In authors opinion KKV gives insufficient recognition to well-known
limitations of mainstream quantitative methods.

Authors convinced that the perspective that quantitative methods should
be considered as a foundation for qualitative methods provides an
excessively narrow understanding of the research process. KKV
overemphasizes the strategy of increasing the number of observations,
and it overlooks the different kinds of observations and the different
ways that data are used in quantitative and qualitative research.

The book is inattentive to the risk that increasing the N may push
scholars toward an untenable level of generality and a loss of
contextual knowledge

**TOOLS AND STANDARDS**

Nevertheless, authors share KKV's view that quantitative and qualitative
methods are founded on essentially similar epistemologies. They argue
Methodological pluralism and analytic rigor can be combined. Because
different research tools can have shared standards for assessing and
applying these tools. Relevant standards must include attention to basic
trade-offs (accuracy, generality, parsimony, and causality) that arise
in conducting research.

Four broad methodological literatures with which many of those research
tools are identified:

1\. Logical and Statistical Foundations of Causal Inference - expresses
considerable skepticism about causal inference based on observational
data (i.e. nonexperemental).

2\. Concepts. Research on concepts, concept formation, and the evolution
of concepts. The insights of this literature suggest that the limited
advice that KKV does give on working with concepts in fact points in the
wrong direction.

3\. Measurement. A major literature located in the fields of
mathematical measurement theory and psychometrics provides researchers
with systematic guidance for measurement. This literature emphasizes,
for example, the contextual specificity of measurement claims,
reinforcing the conviction of many political scientists that knowledge
of context and care in bounding the generality of research findings must
be a central concern in research design. Such guidance is lacking in
KKV.

4\. Causal Inference in Case Studies. A long tradition of writing has
explored tools and strategies of causal inference in case studies: for
example, process tracing and other forms of within-case analysis; the
deliberate selection of "most-likely," "least-likely," and "deviant"
cases; KKV seeks to subsume these tools within its own framework, based
on the norms of large-N quantitative analysis. The case-study literature
in effect turns KKV's argument on its head, suggesting that (a) the
practice of causal inference in qualitative research is viable on its
own terms, and (b) inference in quantitative research can sometimes be
improved through the use of tools strongly identified with the
qualitative tradition.

So each approach has its trade-offs and different scholars should
acknowledge strength and weaknesses of different research approaches.

**TOWARD AN ALTERNATIVE VIEW OF METHODOLOGY**

1.  In the social sciences, quantitative and qualitative research is
    hard to do well. Both suffer from difficulties in causal inference
    (but for different reasons). So the should complement each other
    because they address this challenge in different ways.

2.  Based on statistical theory critiques scholars should take into
    account limitations of each approach.

Mainly they describes issue with quantitative approach.

a.  How much scholars can in fact learn from findings based on
    regression analysis. For regression results to be meaningful,
    analysts must assume, as noted earlier in this chapter, that they
    have begun with the correct statistical model (*Sasha: Which can be
    tricky because we do not really know the nature of relation between
    IVs and DV --linear, square, log or other*)

Another key concern is the capacity to estimate uncertainty using
significance test. There are areas where it is not applicable.

b.  KKV's recommendation that researchers can gain inferential advantage
    in addressing rival explanations by increasing the N of
    observations. First, it is not always possible. Second it pushes
    scholars to compare apples and oranges

c.  Nothing new in this point

<!-- -->

3.  They distinguish between two types of observation:

<!-- -->

a.  Data-set observations -- one of the rows in data set.

b.  Causal-process observations -- observations about context, process,
    or mechanism between DV and IV. The strength of causal-process
    observations lies not in breadth of coverage, but depth of insight.

<!-- -->

4.  The qualitative template can make important contributions to broader
    methodological agendas.

<!-- -->

a.  Depth of the knowledge of the context provides insight into
    potentially significant factors that are not among the variables
    being formally considered (it is connected to 3b)

b.  Mainstream quantitative researchers are sometimes dismissing the
    contribution of inductive analysis. Mainly because of post hoc
    hypothesis reformulation. But quantitative scholars also use various
    models before they find the right one which is basically the same.

c.  Nothing new in this point beyond lets consider both quant and qaual.

<!-- -->

5.  Statistical theory can improve both qualitative and quantitative
    analysis

6.  Scholars must face the challenge of adjudicating between potentially
    conflicting methodological norms.

    a.  Research design involves fundamental trade-offs (based on goals,
        types of observations, and tools) that have to be acknowledged.

    b.  Scholars should develop shared standards (regarding trade-offs)

*Sasha: The rest of the chapter is the short description of the
chapters, which I omit because it is already summary. Don't bother to
read it because it basically states which chapter will expend on points
raised above in more detail.*

## Chapter 9

**Sources of Leverage in Causal Inference: Toward an Alternative View of
Methodology**

*Sasha: this article has a lot of quantitative jargon and terms related
to quantitative research in some places I connected the dots by
providing additional information in brackets using italic*

The key distinction that was sort of downplayed by KKV is distinction
between observational studies and experiment. The difference is in
ability to make inference and reject alternative explanations.

Authors consider three other distinctions: determinate versus
indeterminate research designs, data mining vis-Ã -vis specification
searches, and the assumptions of conditional independence versus the
specification assumption.

**Experiments, Quasi-Experiments, Observational Studies, and Inferential
Monsters**

-   Sharp dichotomy between experimental and observational data.

A quasi-experimental design is typically based on time-series data,
involving a sequence of observations focused on the outcome being
explained. Usually it considered as a stronger alternative to regular
quantitative observational data, however they author here convey the
message that it is basically the same *(I am not sure why though*).

-   KKV's stating point is experimental golden standard. Then KKV
    sometimes seems to confound the tools relevant to experiments and
    those relevant to conventional quantitative research. For example,
    KKV is not clear enough in distinguishing between the independence
    assumption (*in the experiments*) and conditional independence (in
    observational studies).

-   Also, KKV somewhat confusing regarding randomization. It is very
    important to separate two types of randomization: the random
    assignment carried out in most experiments, versus the random
    sampling that is often used in quantitative observational studies.
    KKV in effect lumps together random selection and random assignment
    and create this false separation between large N and small N
    studies.

-   In sum, quantitative and qualitative research face the same problem
    regarding causal inference.

**Mainstream Quantitative Methods versus Statistical Theory**

How effective quantitative analysis can be in achieving valid inference?

Mainstream quantitative methods are a subset of applied statistics.

KKV suggest to rely more on significance test for estimating uncertainty
(*how certain we are in that our result is not received by chance*).
However, the problem of such suggestion is that significance test can
work only if we use random sample which is often not the case for
qualitative research.

One of the way to address this is to use Bayesian statistical analysis
which is largely neglected by KKV.

Reasons why Bayesian statistical approach may be more appropriate for
small n studies:

-   Provides clear structure for research design

-   Allows evaluate level of uncertainty using less formal and more
    nuanced model

-   Provides system that helps in reasoning about the relation between
    the findings of prior research and the insights generated by any
    given small-N study

-   Provides tools for evaluating arguments about necessary and
    sufficient causation

**Determinate versus Indeterminate Research Designs**

-   KKV provide essential criteria of "determinate" (the one that allows
    causal inference) research design:

a.  having a sufficient N in relation to the number of explanatory
    parameters being estimated (*refers to sampling error - the higher N
    the higher chance to receive true mean of the population*)

b.  Avoiding the problem that two or more explanatory variables are
    perfectly correlated (*multicollinearity proble)*

This distinction relies on the standard idea of the power of statistical
tests (*certainty with which we can reject null hypothesis*). This
distinction put small n researcher always on the wrong side. In
addition, this obscure the real distinction between experimental and
observational data (*which means that regardless of the N everybody
sucks compared to experiment)*

-   In addition, this approach pushes scholars to create and test only
    theories that can be tested in a "determinate" research design.

-   Rather than evaluating research designs as being determinate or
    indeterminate, it may be more productive to ask a broader question:
    Are the findings and inferences yielded by a given research design
    **[interpretable]{.underline}**. The interpretability of findings
    and inferences can be increased by many factors, including a larger
    N, a particularly revealing comparative design, a rich knowledge of
    cases and context, well-executed conceptualization and measurement,
    or an insightful theoretical model.

**Data Mining versus Specification Searches**

"data mining" or "data snooping" refers to the practice where researcher
try multiple combination of the variables until the find the best one.

This practice, although very common, usually seen in a bad light. it is
seen as post hoc alteration of your theoretical theory (*which according
to KKV is ok **[only if]{.underline}** you then test your new theory on
new data set, but who have money and time for that?!).*

At the same time, econometric practice of "specification searches"
(*when you look for the right model-linear, log and others*) is, by
contrast, viewed favorably by methodologists as an unavoidable step in
making causal inferences from observational data. Both "data mining" and
"specification searches" represent inductive research. Treating these
inductive practices as a problem can be misleading, if not
counterproductive.

Both quantitative and qualitative researchers routinely adjust their
theories in light of the data---often without taking the further step of
moving to new data sets in order to test the modified theory. We just
should not pretend that it is not happening.

**Conditional Independence or the Specification Assumption** *(oh boy...
hang on!)*

Independence of assignment implies that when we have two groups (A and
B) both groups are very similar. So, if we give treatment to group A it
will have same mean value in the outcome variable as group B (if we give
treatment to group B either). And vice versa both groups presumably
would have same value in the outcome value if we don't give them any
treatment. So basically, this is an assumption that both groups would
have had the same average in the outcome if we would treat the
similarly*. (As you can imagine)* This condition cannot be met because
it is only hypothetical and cannot be tested because treatment and
control group can only be either treatment or control and not both in
the same time. This condition sort of satisfied in experiment when we
use large enough random assignment to the treatment and control groups.

In the observational studies, instead of independence of assignment we
use [conditional independence]{.underline}. This means that there is
another variable or set of variables, which serve as "statistical
controls" and therefore we sort satisfy the condition that compared
groups are different only in their outcome variable. In effect, by
introducing statistical controls into the analysis and then assuming
conditional independence, the researcher turns the observational study
into something akin to an experiment. However, it is obviously vital to
remember that the assumption of conditional independence, like the
assumption of independence, is hard to test.

-   [The specification assumption (]{.underline}*this is what usually
    used by normal observational study*)

In the context of a regression model, the specification assumption is
the claim that the included independent variables are statistically
unrelated to the error term (*error term refers to all other variables
that could be added to the model*). The basic problem is that there is
always threat that researcher omitted variable that is important
(missing bias). Second problem is endogeneity bias.

(*if we add to regression variable that is correlated to error term and
to DV and not correlated to our IVs ... but why this is a problem I
don't know)*

-   [Both]{.underline} assumptions ([conditional
    independence]{.underline}, [specification assumption]{.underline})
    are hard to test, and no analyst can ever prove that an
    observational study meets either assumption. Which mean that we
    cannot rely solely on correlation-based model we need to support it
    with either experiment or causal-process observations.

**[Four approaches to the qualitative versus quantitative
distinction]{.underline}**

**Level of Measurement -** Nominal data qualitative while ordinal,
interval and ratio is quantitative. Higher levels of measurement are
yielding more analytic leverage, because they provide more fine-grained
differentiation among cases, but it comes with more complex assumptions
that hard to meet.

**Size of the N -** small-N and large-N research. cut-point might be
located somewhere between ten and twenty cases. Some scholars with
relatively large n may use qualitative method and vice versa.

**Statistical Tests.** Quantitative use statistical test in order to
estimate power of connection between variables**,** but as we saw there
are a lot of assumption that are hard to meet.

**Thick versus Thin Analysis.** Qualitative research routinely utilizes
thick analysis, which place great reliance on a d[etailed]{.underline}
knowledge of cases. It can greatly strengthen description and causal
assessment. It is also related to discussion of case-oriented versus
variable-oriented research.

**Drawing Together the Four Criteria**

We would certainly classify as qualitative a study that places central
reliance on nominal categories, focuses on relatively few cases, makes
little or no use of statistical tests, and places substantial reliance
on thick analysis. By contrast, a study based primarily on interval- or
ratio-level measures, a large N, statistical tests, and a predominant
use of thin analysis is certainly quantitative.

But should remember that there are intermediate alternatives.

**[Cases versus observations]{.underline}**

**Cases** correspond to the political, social, institutional, or
individual entities or processes about which information is collected.
(number of rows in the data)

**Observation** has a commonsense meaning: it is an insight or piece of
information recorded by the researcher about a specific feature of the
phenomenon or process being studied. (can be value of the variable for a
single case.

Alternatively, **observation** is the collection of scores for a given
case, on the dependent variable and all the independent variables in
other words it is a "data point". which in a two-dimensional scatterplot
corresponds to the scores of the independent and dependent variables.
The purpose of this second definition of observation is to highlight
that central inferential role. (this approach solves the problem of
degree of freedom for small n studies).

Authors use word score or to piece of data (when we talk about first
definition of observation) and use data-set observation (when they talk
about second definition)

**[Data-set observations versus causal-process
observations]{.underline}**

Here authors introduce additional term - causal-process observation. It
is an insight or piece of data that provides information about context
or mechanism and contributes a different kind of leverage in causal
inference.

A scholar who has discovered a fruitful causal-process observation in
one case might then proceed to systematically score many cases on this
same analytic feature and add the new scores to an existing collection
of data-set observations.

-   Inference based on causal process observations does not involve the
    approach of what we are calling mainstream quantitative methods

KKV's framework is designed for analyzing data-set observations and not
causal-process observations. Our point, by contrast, is that
causal-process observations offer a different approach to inference.
Causal-process observations are valuable, in part, because they can fill
gaps in conventional quantitative research.

In sum, the rich causal insights that qualitative researchers may gain
from thick analysis can often be supplemented by systematic cross-case
comparison using data-set observations, statistical tests, and thin
analysis. Similarly, the correlation-based inferences that quantitative
researchers derive from data-set observations can often be enhanced by
causal-process observations.

**[Examples of Causal-Process Observations]{.underline}**

1.  Brady's causal-process observations regarding 10,000 votes
    potentials votes for Bush during 2000 election. Brady by analyzing
    actual events of election day shows that the maximum number of votes
    that Bush could have lost was 224, and that the actual loss was
    probably just a few dozen votes.

2.  Stokes's Analysis of the dramatic economic policy shifts toward
    neoliberalism initiated by several Latin American presidents between
    1982 and 1995. She has her sort of quantitative analysis and then
    she provides detailed step-by-step account of how three presidents
    decided to abandon the more populist rhetoric and adopt a package of
    neoliberal reforms. Stokes shows how in one of the examples a
    sequence of encounters with major international and domestic leaders
    exposed president to certain macroeconomic arguments, and these
    arguments convinced him that economy was headed for disaster if
    neoliberal reforms were not adopted.

3.  Tannenwald's analysis regarding normative nuclear taboo. She used
    documentary evidence that key U.S. decision makers thought the use
    of nuclear weapons would be a disaster in terms of world public
    opinion and, or "offensive to all morality". In parallel top-level
    debates on the potential use of nuclear weapons during the Vietnam
    War, one key meeting reached the conclusion that "use of atomic
    weapons is unthinkable" for normative reasons.

**[Implications of Contrasting Types of Observations]{.underline}**

**Qualitative versus Quantitative**

Large-N quantitative researchers may routinely use large numbers of
data-set observations and many fewer causal-process observations. By
contrast, small-N qualitative researchers may use few data-set
observations and a great many causal-process observations. However, the
two types of observations (data set and causal-process), used together,
can provide strong inferential leverage in both traditions of research.

**Adding Observations and Adding Variables: Consequences for the N,
Degrees of Freedom, and Inferential Leverage.**


**Implications for Research Design**

Although the advice to increase the number of data-set observations is
sometimes valuable, it may simply be distracting for researchers who
have deliberately focused on explaining a small number of important
outcomes. These researchers may find that collecting relevant
causal-process observations is more helpful.

**Missing Data**

With data-set observations, missing data can be a serious issue. Almost
by definition, the issue of missing data does not arise in the same way
for causal process observations. Thus, one or a few causal-process
observations may provide great leverage in making inferences.

**Standard Quantitative Tools versus Careful Analysis of Causal-Process
Observations**

KKV are wrong about the need to subordinating causal-process
observations to a conventional quantitative framework

Making an inference from a smoking gun (*refers to one of the types of
process tracing evidence*) does not require a large N in any traditional
sense.

**[Balancing methodological priorities: technification and the quest for
shared standards]{.underline}**

The trend toward technification (more complex statistical tools) can
impose substantial costs. It can lead to replacing a simple and
appropriate tool with an unnecessarily complex one. It can sometimes
distance analysts from the detailed knowledge of cases and contexts that
is an invaluable underpinning for any inference, whether derived through
complex research procedures or simpler tools.
