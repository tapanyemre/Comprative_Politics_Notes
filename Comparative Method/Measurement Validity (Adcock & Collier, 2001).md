# Metadata
## Identifiers
title: Measurement Validity: A Shared Standard for Qualitative and Quantitative Research 
author(s): Robert #Adcock and David #Collier
year: #y2001 
citation:
link:

## Linkers

sub-theme(s): #Methodology #Mixed_Method #Qualitative #Quantitative #Measurement #conceptualization 
keywords:

## TLDR

RQ:
Main Argument:
DV:
IV:
Cases:
Main Findings:
Data:
Method:
Empirical Evidence: 
How does the evidence map onto the theoretical argument: 

# Long Summary

**Measurement Validity: A Shared Standard for Qualitative and
Quantitative Research**

**Robert Adcock and David Collier**

[Set up:]{.underline} Little attention has been paid in political
science to measurement validity - even though scientists frequently make
claims that assume the validity of observations and/or measurements.

[Goal:]{.underline} Addressing the gap by developing four specific
themes that can be applied to be quantitative and qualitative research.

-   When linking concepts to observations a question pops up: "**Do the
    observations meaningfully capture the ideas contained in the
    concepts**?" (529)

-   And: **Does the operationalization and the scoring of cases properly
    reflect the concepts the researcher intends to measure**? (529)

-   Measurement validity is distinct from causal inference → can be
    further separated into external and internal validity
    (Cook/Campbell)

-   Not much attention has been given to the issue of measurement
    validity; it can, however, address four problems in Political
    Science.

    -   Creating a shared standard for qualitative and quantitative
        research

        -   Authors propose a framework that incorporates both

    -   Relationship between measurement validity and disputes about the
        meaning of concepts

        -   Authors will make it clear that there are two types of
            disputes

    -   Contextual specificity of measurement validity (issue valid in
        one context, not valid in another)

        -   Authors attempt to create a middle ground between
            universalising and particularizing

    -   Confusing language to discuss alternative procedures for
        measurement validation

        -   Authors will clarify the issue

**Overview of Measurement Validity**

-   Should be understood in relation to issues that arise in moving
    between concepts and observations (530)

-   They establish the model below, which is the glue that holds their
    entire paper together.

-   Valid measurement is achieved when scores properly measure what they
    were supposed to measure (see KKV)

-   However: to further specify the idea of measurement validity the
    authors specify both ends of the connection between concepts and
    scores

    -   Concept end: measurement validity focuses on the connection
        between observations and systematized concepts

    -   Scores end: they are never looked at in isolation, given meaning
        through connection to systematized concepts

**→ "A measurement is valid when the scores (level 4), derived from a
given indicator (level 3) can meaningfully be interpreted in terms of
the systematized concept (level 2) that the indicator seeks to
operationalize." (531)**

**Errors, Reliability, and Validity**

-   Measurement error can be systematic or random

    -   Systematic: bias

    -   Random: repeated applications yield inconsistent results →
        reliability issue

-   Validity involves systematic errors

-   Reliability involves random errors

-   Unreliable scores can still be considered valid by some.

-   Others do not like scores as valid because of too many random
    errors. They would require the absence of both types of errors to
    consider them valid.

<!-- -->

-   The authors of the article do not want to "adjudicate" between these
    stances.

    -   Their focus: systematic errors that come up when the connections
        between systematized concepts, indicators, and scores are badly
        developed **(it becomes an issue of validity,** *and not so much
        the background concept as usually it is done to measure
        validity**)*****.**

**Forming the Systematized Concept**

-   Different types of concepts exit (straightforward "triangle" to
    other extreme "democracy")

-   Intertwined process, because need concept to create theory, but
    theory needed to create concept, etc. (circular)

-   Three traps to avoid when forming a systematized concept:

    -   Not everything is up for grabs (one can drift too far out and be
        shunned by everybody) → only real choices

    -   Don't promise the world with that one concept (do not
        automatically assume all other concepts ruled out) → justify
        your choice with specific arguments

    -   Don't just talk about your concept in one sentence, flesh it out

**Fine-Tuning the Systematized Concept**

-   During validation process new conceptual ideas can be introduced
    (see image)

-   The authors call them "friendly amendments" because they do not
    completely throw overboard the established systematized concept

**Validity Contextual Specificity, and Equivalence**

-   Same score on an indicator may have different meanings in different
    contexts

-   Poses an issue for Political Science

    -   Some scholars have even questioned whether it is possible to
        even create law like explanations for political phenomena (534)

**Contextual Specificity in Political Research**

-   Examples where it becomes an issue

    -   Cross-national survey research

    -   Survey responses over time

    -   General claims by constructivists in IR (quite the extreme vs.
        realists' anarchy shows unchanging essence of human nature)

    -   Key → establishing equivalence across diverse contexts and if
        necessary → adopt context specific measures

**Establishing Equivalence**

-   Context specific domains of observation necessary as sometimes broad
    strokes can overlook aspect

-   Can also be done at the indicator level, context-specific indicators
    and "adjusted common indicator", which is weighted to compensate for
    contextual differences (i.e. political participation studies, or
    researching thresholds to be considered democracy, health care
    policies)

-   Limitations: sometimes, based on the researcher and their goals it
    is not wise to weight and adjust, a standard definition of a concept
    might be more appropriate

**Validation**

-   First phase:

<!-- -->

-   1950s and 1960s first unified approach to understanding what
    validity (or as authors say validation is): holy trinity

    -   *Content validity* (degree to which an indicator represents the
        universe of content)

    -   *Criterion validity* (scores produced by an indicator are
        empirically associated with scores for other variables)

    -   *Construct validity* (assessing whether given indicator is
        empirically associated with other indicators in a way that
        conforms to theoretical expectations)

-   Major critique: these three shouldn't be seen as individual aspects
    but should be unified in one large concept

-   Second phase:

    -   Reconceptualizing construct validity and relation to content and
        criterion

    -   In academia almost consensus that content and criterion are two
        types of evidence supporting construct validity

    -   Apparently content and criterion are of limited use for
        political scientists (i.e.Carmines/Zeller, Bollen)

    -   Construct validity has become synonymous with measurement
        validity

    -   The authors use construct validity in the context of political
        science to highlight that it usually means a very specific
        procedure to determine validity rather than a general idea of
        valid measurement. They expand on that notion by distinguishing
        between two larger procedure concepts.

        -   Some procedures rely on descriptive explanations, concerned
            whether specific attributes are understood as aspects of the
            same phenomenon

            -   **convergent/discriminant validation**

        -   Some procedures rely on explanatory causal relations as
            foundation against which measurement validity is assessed.

            -   **Nomological validation (in political research
                construct validity)**

**Three Types of Measurement Validation: Qualitative and Quantitative
Examples**

-   Lastly the authors go through content validation, convergent
    (discriminant) validation, and construct (nomological) validation

-   Analyzing each type by posing a question that could be discussed by
    both qualitative and quantitative scholars

    -   *Content Validation:* (looking at the image), Does a given
        indicator (level 3) adequately capture the full content of the
        systematized concept (level 2)?

    -   *Convergent Validation:* Are the scores (level 4) produced by
        alternative indicators of a given systematized concept (level 2)
        empirically associated and thus convergent?

    -   *Construct Validation*: In a domain of research in which a given
        causal hypothesis is reasonably well established, the authors
        ask: Is this hypothesis again confirmed when the cases are
        scored (level 4) with the proposed indicator (level 3) for a
        systematized concept (level 2) that is one the variables in the
        hypothesis? (yes considered evidence for validity)

-   *Jenny: I will not bore you (and myself) with each and every example
    and the discussions and their limitations (538-543)*

-   Fact ist: none of the specific types of validation stand on their
    own and can individually establish validity → each of them provides
    evidence for an overall assessment

    -   Content: adequacy of content of indicators

    -   Convergent: focuses on shared and nonshared variance among
        indicators that researcher is looking at

    -   Construct: (baseline of established causal hypothesis) teases
        out additional aspects in measurement validity not addressed by
        convergent

    -   Validation is a multifaceted process

    -   One needs to differentiate between background concept and the
        systematized concept

    -   Context-specificity is useful in a lot of cases (domain and/or
        indicators) → middle position possible through that

    -   The authors basic questions in validation allow them to be
        applied to both quantitative and qualitative research, even
        though one needs to remember that often times these two camps
        look at different questions/have different goals/use different
        tools.
